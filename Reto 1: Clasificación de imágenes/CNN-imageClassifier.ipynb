{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0072fb2-16f7-4bef-9ce2-2937a0c4de2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip oracle_CV.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a89d9-8d18-4478-9a86-3feaca424026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the neccessary libraries.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd93e8-2abe-4962-904a-ad245c452d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store the training an testing images and labels with the info in the csv's\n",
    "\n",
    "# Read the csv's\n",
    "train_df = pd.read_csv(r\"train.csv\")\n",
    "test_df = pd.read_csv(r\"test.csv\")\n",
    "\n",
    "# Create the training and testing images and labels\n",
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "\n",
    "# Training images and labels\n",
    "for i in range(len(train_df)):\n",
    "    img = PIL.Image.open(os.path.join(r\"\", train_df.iloc[i,1]))\n",
    "    img = img.convert(\"RGB\") # Convert to RGB. This is needed to preserve the 3 color channels of the image.\n",
    "    train_images.append(np.array(img)) # dtype=uint8 by default\n",
    "    train_labels.append(train_df.iloc[i,2])\n",
    "\n",
    "print(len(train_images))\n",
    "print(len(train_labels))\n",
    "\n",
    "# Testing images and labels\n",
    "for i in range(len(test_df)):\n",
    "    img = PIL.Image.open(os.path.join(r\"\", test_df.iloc[i,1]))\n",
    "    img = img.convert(\"RGB\") # Convert to RGB. This is needed to preserve the 3 channels of the image.\n",
    "    test_images.append(np.array(img))\n",
    "\n",
    "print(len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59360ce2-be3a-42a3-a874-89d3f1f810f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(train_images[4520].dtype)\n",
    "#print(train_images[4520].shape)\n",
    "\n",
    "# Visualize an image\n",
    "plt.figure()\n",
    "plt.imshow(train_images[4529])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4cf2bc-1d18-4c91-b5e2-1488cf478254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define class names for each label\n",
    "class_names = ['Burger', 'Chicken', 'Donut', 'Fries', 'Sausage',\n",
    "               'Pizza', 'Sandwich', 'Panini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1833aa9-4db0-43ac-a421-0d7734fdfdc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resize images (in batches so colab doesn't run out of memory)\n",
    "\n",
    "batch_size = 5 # Set batch size\n",
    "target_size = (200, 200) # Desired size for all images\n",
    "\n",
    "# Calculate number of batches\n",
    "num_batches = int(np.ceil(len(train_images) / batch_size))\n",
    "\n",
    "train_images_resized = np.empty((len(train_images), *target_size, 3), dtype=np.uint8) # Empty list to store resized images\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start = i * batch_size\n",
    "    end = min((i + 1) * batch_size, len(train_images))\n",
    "    train_images_batch = train_images[start:end]\n",
    "    \n",
    "    for j, img in enumerate(train_images_batch):\n",
    "        # Resize each image using cubic interpolation\n",
    "        res = cv2.resize(img, dsize=target_size, interpolation=cv2.INTER_CUBIC)\n",
    "        #res = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
    "        # Append resized image to resized list\n",
    "        train_images_resized[start + j] = res\n",
    "\n",
    "train_images = train_images_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a0e14-178a-4dc4-96e3-7285057ca2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f657efa5-2d47-46a5-a25c-3e4493a332b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 5 # Set batch size\n",
    "target_size = (200, 200) # Desired size for all images\n",
    "\n",
    "# Calculate number of batches\n",
    "num_batches = int(np.ceil(len(test_images) / batch_size))\n",
    "\n",
    "test_images_resized = np.empty((len(test_images), *target_size, 3), dtype=np.uint8) # Empty list to store resized images\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start = i * batch_size\n",
    "    end = min((i + 1) * batch_size, len(test_images))\n",
    "    test_images_batch = test_images[start:end]\n",
    "    \n",
    "    for j, img in enumerate(test_images_batch):\n",
    "        # Resize each image using cubic interpolation\n",
    "        res = cv2.resize(img, dsize=target_size, interpolation=cv2.INTER_CUBIC)\n",
    "        #res = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
    "        # Append resized image to resized list\n",
    "        test_images_resized[start + j] = res\n",
    "\n",
    "test_images = test_images_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f3ce1e-2fe8-4346-87f3-6607373a7383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(train_images[0].shape)\n",
    "# Visualize an image\n",
    "plt.figure()\n",
    "plt.imshow(train_images[566])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a4fe37-c09c-4f50-8be6-df338d3b4cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize 25 images\n",
    "plt.figure(figsize=(10,10))\n",
    "x = 190\n",
    "for i in range(x, x + 25):\n",
    "    plt.subplot(5,5,i-(x-1))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# idx_train 10524 has label 4 when it should be 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb04650-b325-4287-9b06-ab9172532e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data augmentation layers\n",
    "# Try different things\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\",\n",
    "                      input_shape=(200,\n",
    "                                  200,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomTranslation(height_factor=0.15, width_factor=0.15)\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c719c9bb-5ed0-43c8-9a5a-deaab758ff56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', # Monitor the validation loss\n",
    "    patience=10, # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True # Restore the best weights from the best epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb0b4b-d592-4256-a39a-a11d54fda58f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential([\n",
    "    data_augmentation, # Data augmentation\n",
    "    layers.Rescaling(1./255, input_shape=(200, 200, 3),),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2be065-1755-4009-83b3-c0d05ca3df9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed048b26-8fb5-4150-9f42-37b07dc7a763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_images, \n",
    "                    train_labels, \n",
    "                    validation_split=0.1, # Use 10% of the training data as validation data\n",
    "                    epochs=100,\n",
    "                    callbacks=[early_stopping]) # , validation_data=(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d173b5-8045-4eb4-a128-8b0bc13a7af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb58c547-546f-46cd-b02e-fb33be72e87c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d8dd2-527f-4872-ab11-8e2ae8ede1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model072.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4da646-1daa-4081-ab8b-cebb96f51abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n",
    "predictions = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f445abd-230a-440e-92a1-e2353798785a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create JSON file with predictions\n",
    "\n",
    "# Create a dictionary with the predictions\n",
    "predictions_dict = {}\n",
    "for i in range(0, len(predictions)):\n",
    "    predictions_dict[str(i)] = (int)(np.argmax(predictions[i]))\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open('predictions.json', 'w') as f:\n",
    "    json.dump(predictions_dict, f)\n",
    "\n",
    "# Ver resultados subiendo el json a la web del reto\n",
    "#Your F1-score is: 0.764 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52615d0d-aaa0-4f01-a38c-eeeb006505e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
